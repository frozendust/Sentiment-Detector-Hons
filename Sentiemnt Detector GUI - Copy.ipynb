{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "\n",
    "    import pickle\n",
    "    import nltk\n",
    "    #imports the list of stop words.\n",
    "from nltk.corpus import stopwords\n",
    "    #Used to tokenize the text into a sentace or just words.\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "    #imort regular exprasions\n",
    "import re\n",
    "    #Import text blob for sentiment demo\n",
    "from textblob import TextBlob\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "\n",
    "\n",
    "stopWords = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def say_hi():\n",
    "    tkinter.Label(window, text = \"Hi\").grid(columnspan = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def User_Tweet(Tweet):\n",
    "    import pickle\n",
    "    import nltk\n",
    "    #imports the list of stop words.\n",
    "    from nltk.corpus import stopwords\n",
    "    #Used to tokenize the text into a sentace or just words.\n",
    "    from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "    #imort regular exprasions\n",
    "    import re\n",
    "    #Import text blob for sentiment demo\n",
    "    from textblob import TextBlob\n",
    "\n",
    "    import pandas as pd  \n",
    "    import numpy as np  \n",
    "\n",
    "\n",
    "    stopWords = set(stopwords.words('english')) \n",
    "    \n",
    "    tweet =Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = tkinter.Tk()\n",
    "window.title(\"Sentiment Detector GUI\")\n",
    "label = tkinter.Label(window, text = \"Hello this is a Sentiemnt Detector for Twitter messages.\").grid(columnspan = 2)\n",
    "label = tkinter.Label(window, text = \"Please enter the message you want to dectect \\n then click the Dectect button\").grid(columnspan = 2)\n",
    "\n",
    "#top_frame = tkinter.Frame(window).pack()\n",
    "btn1 = tkinter.Button(window, text = \"Detect?\", fg = \"Black\", command = say_hi).grid(row = 3, column=0) \n",
    "tkinter.Entry(window).grid(row = 3, column = 1)\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "#imports the list of stop words.\n",
    "from nltk.corpus import stopwords\n",
    "#Used to tokenize the text into a sentace or just words.\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#imort regular exprasions\n",
    "import re\n",
    "#Import text blob for sentiment demo\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "\n",
    "\n",
    "stopWords = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User tweet evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet = 'Hello i hate it when i have to pull a all nighter all the time it sucks.'\n",
    "tweet = 'Hello i love being here im my hobors class it is great.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textProcess(SentiText): \n",
    "    \n",
    "    stopWords = set(stopwords.words('english')) \n",
    "    SentiText = SentiText.lower()                                     #convert to lowercase\n",
    "    \n",
    "    pattern = r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*' \n",
    "    SentiText= re.sub(pattern, \"\", SentiText)                         # remove url\n",
    "    \n",
    "    pattern = r\"[\\d]\"                           \n",
    "    SentiText= re.sub(pattern, \"\", SentiText)                         # remove numbers\n",
    "    \n",
    "    pattern = r\"[^\\w]\"\n",
    "    SentiText= re.sub(pattern, \" \", SentiText)                        # remove commas and puntication\n",
    "    \n",
    "    SentiText = SentiText.strip()                                     # remove white spaces\n",
    "    \n",
    "    SentiText = word_tokenize(SentiText)                              # tokenize sentance\n",
    "    \n",
    "    SentiText = [word for word in SentiText if not word in stopWords] # remove Stop words\n",
    "    return SentiText\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'love', 'im', 'hobors', 'class', 'great']"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = textProcess(tweet)\n",
    "tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' hello love im hobors class great']\n"
     ]
    }
   ],
   "source": [
    "palcer=\"\"\n",
    "for i in (tweet):\n",
    "    palcer = palcer + \" \" + i\n",
    "\n",
    "tweet = palcer\n",
    "tweetArray[0] = tweet\n",
    "print(tweetArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corpus creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>joeof jonas ur mean disown u haha jk yeah u p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>djeejay josh baby must hurt bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>azraeel pretty cool shame ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>myspace pretty facebook twitter better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>life mars great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>ali_i_am_beatz new life urs got u treating li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>work go teaching man great day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>makefate nighty night always eat ice cream us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>meriel awww ull get soon enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>dont think jb movie coming cinema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>denawilliams hope wonderful birthday dena hap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>miss boteros last night fun long time back fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>violetph gods sake even birthday yet need coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>omg cant beleive use thing guys c pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>amber_benson loved continue delight us amber ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>whew imissyou bioblock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>ate first ripe strawberry garden bit tart yummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>heading beach sunday monday heck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>jeriellsworth read artical uk national news p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>watch insomnia pop tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>writing new story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>syzygy got past today test f ooh sounds deep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>yehudaberg true sometimes hard way live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>link preview jbs songs stuido verson nick mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>nobodylkl alone trying get next day year head...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>remember eyes ever puffy guess days crying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>nothings impossible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>ugh someone shoot goin sanford god hate mornings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>quot extremely grateful opportunity play char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>0</td>\n",
       "      <td>ive got spares urgh much work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>4</td>\n",
       "      <td>drinking green tea fresh melissa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>4</td>\n",
       "      <td>markusgiesen yes escaping work multiple line ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>0</td>\n",
       "      <td>markusfeehily aahh sorry hear r problems tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>0</td>\n",
       "      <td>got back dinner one teeth killin idk gon na k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>0</td>\n",
       "      <td>mrshowstopper argh stopped tweet let time bor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>4</td>\n",
       "      <td>caut un serviciu de photosharing care sa dea ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>4</td>\n",
       "      <td>renatak got bablefish firmly planted ear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>0</td>\n",
       "      <td>might without computer wanting start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>0</td>\n",
       "      <td>working home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>4</td>\n",
       "      <td>another episode friends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>0</td>\n",
       "      <td>half class called retarded hurt real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>4</td>\n",
       "      <td>bought holiday clothes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>0</td>\n",
       "      <td>r income days wish could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>4</td>\n",
       "      <td>back ish km walk yes parked near good dog fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>0</td>\n",
       "      <td>watching moldizzle get ready big girls weeken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>4</td>\n",
       "      <td>looking twitter works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>0</td>\n",
       "      <td>dippindots craving nice bowl dippin dots mayb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>0</td>\n",
       "      <td>simonth vid yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>0</td>\n",
       "      <td>woke instead good news amath okay though frea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>0</td>\n",
       "      <td>peterfacinelli gilbirmingham billy_burke show...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>4</td>\n",
       "      <td>listening blink cant wait reunion tour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>0</td>\n",
       "      <td>wtf memcached keys spaces would handy client ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>4</td>\n",
       "      <td>rhettroberts quot circus quot album uk deluxe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>4</td>\n",
       "      <td>shinra_reno pets know sorry something tall bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>f felipebaby ruins many spins sweepstake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>4</td>\n",
       "      <td>jkozuch anything say squarespace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4</td>\n",
       "      <td>goooodnighttttt cassy house tomorrow woo hoo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>4</td>\n",
       "      <td>skyefairy love photos cousin noelle took real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>someone please open decent cafe trawalla aven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment                                            Message\n",
       "0             0   joeof jonas ur mean disown u haha jk yeah u p...\n",
       "1             0                    djeejay josh baby must hurt bad\n",
       "2             0                       azraeel pretty cool shame ps\n",
       "3             4             myspace pretty facebook twitter better\n",
       "4             4                                    life mars great\n",
       "5             0   ali_i_am_beatz new life urs got u treating li...\n",
       "6             4                     work go teaching man great day\n",
       "7             4   makefate nighty night always eat ice cream us...\n",
       "8             4                    meriel awww ull get soon enough\n",
       "9             0                  dont think jb movie coming cinema\n",
       "10            4   denawilliams hope wonderful birthday dena hap...\n",
       "11            4   miss boteros last night fun long time back fe...\n",
       "12            0   violetph gods sake even birthday yet need coo...\n",
       "13            0         omg cant beleive use thing guys c pictures\n",
       "14            4   amber_benson loved continue delight us amber ...\n",
       "15            0                             whew imissyou bioblock\n",
       "16            4    ate first ripe strawberry garden bit tart yummy\n",
       "17            4                   heading beach sunday monday heck\n",
       "18            4   jeriellsworth read artical uk national news p...\n",
       "19            0                         watch insomnia pop tonight\n",
       "20            4                                  writing new story\n",
       "21            4   syzygy got past today test f ooh sounds deep ...\n",
       "22            4            yehudaberg true sometimes hard way live\n",
       "23            4   link preview jbs songs stuido verson nick mil...\n",
       "24            4   nobodylkl alone trying get next day year head...\n",
       "25            0         remember eyes ever puffy guess days crying\n",
       "26            4                                nothings impossible\n",
       "27            0                                              sleep\n",
       "28            0   ugh someone shoot goin sanford god hate mornings\n",
       "29            0   quot extremely grateful opportunity play char...\n",
       "...         ...                                                ...\n",
       "9970          0                      ive got spares urgh much work\n",
       "9971          4                   drinking green tea fresh melissa\n",
       "9972          4   markusgiesen yes escaping work multiple line ...\n",
       "9973          0   markusfeehily aahh sorry hear r problems tech...\n",
       "9974          0   got back dinner one teeth killin idk gon na k...\n",
       "9975          0   mrshowstopper argh stopped tweet let time bor...\n",
       "9976          4   caut un serviciu de photosharing care sa dea ...\n",
       "9977          4           renatak got bablefish firmly planted ear\n",
       "9978          0               might without computer wanting start\n",
       "9979          0                                       working home\n",
       "9980          4                            another episode friends\n",
       "9981          0               half class called retarded hurt real\n",
       "9982          4                             bought holiday clothes\n",
       "9983          0                           r income days wish could\n",
       "9984          4   back ish km walk yes parked near good dog fri...\n",
       "9985          0   watching moldizzle get ready big girls weeken...\n",
       "9986          4                              looking twitter works\n",
       "9987          0   dippindots craving nice bowl dippin dots mayb...\n",
       "9988          0                                    simonth vid yet\n",
       "9989          0   woke instead good news amath okay though frea...\n",
       "9990          0   peterfacinelli gilbirmingham billy_burke show...\n",
       "9991          4             listening blink cant wait reunion tour\n",
       "9992          0   wtf memcached keys spaces would handy client ...\n",
       "9993          4   rhettroberts quot circus quot album uk deluxe...\n",
       "9994          4   shinra_reno pets know sorry something tall bu...\n",
       "9995          0           f felipebaby ruins many spins sweepstake\n",
       "9996          4                   jkozuch anything say squarespace\n",
       "9997          4   goooodnighttttt cassy house tomorrow woo hoo ...\n",
       "9998          4   skyefairy love photos cousin noelle took real...\n",
       "9999          0   someone please open decent cafe trawalla aven...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sample_Sentiment_Data_processes = pd.read_csv('SentiSample_10000_processed.csv', encoding = \"ISO-8859-1\")\n",
    "Sample_Sentiment_Data_processes = Sample_Sentiment_Data_processes.drop(columns=[\"Unnamed: 0\"])\n",
    "Sample_Sentiment_Data_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_Sentiment_Data_processes.isnull().any()\n",
    "Sample_Sentiment_Data_processes=Sample_Sentiment_Data_processes.fillna(\"placeholder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9205)\t0.3489400982767751\n",
      "  (0, 7230)\t0.3706930921477705\n",
      "  (0, 6694)\t0.5489591035076415\n",
      "  (0, 6276)\t0.3992187802141089\n",
      "  (0, 2859)\t0.5292406895250635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer=TfidfVectorizer()\n",
    "vectorizer.fit(Sample_Sentiment_Data_processes.Message)\n",
    "#results=vectorizer.fit_transform([document])\n",
    "results=vectorizer.transform(tweetArray)\n",
    "#results=vectorizer.fit_transform([document])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 17524)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "filename = 'finalized_model_10000.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(results)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "if (result == 0):\n",
    "    print (\"Negative\")\n",
    "else:\n",
    "    print(\"Positive\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
